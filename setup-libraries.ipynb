{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data with Spark HATS\n",
    "\n",
    "This Hands on Advanced Tutorial Session \n",
    "([HATS](http://lpc.fnal.gov/programs/schools-workshops/hats.shtml)) is\n",
    "presented by the LPC to demonstrate a CMS analysis using\n",
    "[Apache Spark](http://spark.apache.org/),\n",
    "[Spark-ROOT](https://github.com/diana-hep/spark-root),\n",
    "[Histogrammar](http://histogrammar.org/), and\n",
    "[MatplotLib](https://matplotlib.org/). After introducing Spark, students\n",
    "will learn the steps needed to perform a basic measurement\n",
    "of the Z-boson mass using CMS data recorded in 2016.\n",
    "\n",
    "*Note* - To perform any exercise, these notebooks must be open\n",
    "within [Jupyter](https://jupyter.org). GitHub has a very nice\n",
    "notebook renderer, but it is read-only and won't actually\n",
    "execute any code. Information on how to access Jupyter can\n",
    "be found in the [README](./README.md).\n",
    "\n",
    "\n",
    "\n",
    "Setup Instructions\n",
    "==========\n",
    "\n",
    "These instructions need to be run once to load the requisite libraries for the tutorial.\n",
    "\n",
    "Jupyter has the concept of _kernels_, which are independent execution environments. They don't\n",
    "even have to be Python, kernels for other languages exist as well.\n",
    "\n",
    "By loading a separate kernel for each project, we avoid the complication of different\n",
    "components/projects having weird interactions, ultimately helping reproducibility.\n",
    "\n",
    "We first produce a new virtualenv with the libraries we require, then we teach Jupyter\n",
    "about this new environment with the ipython executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base prefix '/usr'\n",
      "New python executable in /home/cms.kmotaama/spark-hats/hats-spark36/bin/python3.6\n",
      "Also creating executable in /home/cms.kmotaama/spark-hats/hats-spark36/bin/python\n",
      "Installing setuptools, pip, wheel...\n",
      "done.\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-5.3.0-py3-none-any.whl (119 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Collecting histogrammar\n",
      "  Cloning https://github.com/histogrammar/histogrammar-python.git (to revision 1.0.x) to /tmp/pip-install-w90r8ddv/histogrammar\n",
      "Collecting jupyter-client\n",
      "  Downloading jupyter_client-6.1.3-py3-none-any.whl (106 kB)\n",
      "Collecting tornado>=4.2\n",
      "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
      "Collecting traitlets>=4.1.0\n",
      "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting ipython>=5.0.0\n",
      "  Downloading ipython-7.15.0-py3-none-any.whl (783 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting jupyter-core>=4.6.0\n",
      "  Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
      "Collecting pyzmq>=13\n",
      "  Downloading pyzmq-19.0.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.6.1-py3-none-any.whl (914 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./hats-spark36/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel) (47.1.1)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.17.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.5-py3-none-any.whl (351 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting parso>=0.7.0\n",
      "  Downloading parso-0.7.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.4-py2.py3-none-any.whl (30 kB)\n",
      "Building wheels for collected packages: histogrammar, tornado\n",
      "  Building wheel for histogrammar (setup.py): started\n",
      "  Building wheel for histogrammar (setup.py): finished with status 'done'\n",
      "  Created wheel for histogrammar: filename=histogrammar-1.0.12-py3-none-any.whl size=279250 sha256=390a66398819df7bad7fab6774213bb8cc448e886123c9f012787e58b8ad9b75\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p4f0p1lt/wheels/0a/7d/c7/b7d8b80a098c533208f513d4b98067d9bb27206025b3f6a9bf\n",
      "  Building wheel for tornado (setup.py): started\n",
      "  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Created wheel for tornado: filename=tornado-6.0.4-cp36-cp36m-linux_x86_64.whl size=422941 sha256=7e3dce18a54756ed5eafa6a2f4c52f2047e5a36f2edd36becf6502e710ae6d24\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p4f0p1lt/wheels/37/a7/db/2d592e44029ef817f3ef63ea991db34191cebaef087a96f505\n",
      "Successfully built histogrammar tornado\n",
      "Installing collected packages: six, python-dateutil, tornado, ipython-genutils, decorator, traitlets, jupyter-core, pyzmq, jupyter-client, pygments, pickleshare, ptyprocess, pexpect, backcall, parso, jedi, wcwidth, prompt-toolkit, ipython, ipykernel, kiwisolver, pyparsing, cycler, numpy, matplotlib, py4j, histogrammar\n",
      "Successfully installed backcall-0.2.0 cycler-0.10.0 decorator-4.4.2 histogrammar-1.0.12 ipykernel-5.3.0 ipython-7.15.0 ipython-genutils-0.2.0 jedi-0.17.0 jupyter-client-6.1.3 jupyter-core-4.6.3 kiwisolver-1.2.0 matplotlib-3.2.1 numpy-1.18.5 parso-0.7.0 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.5 ptyprocess-0.6.0 py4j-0.10.9 pygments-2.6.1 pyparsing-2.4.7 python-dateutil-2.8.1 pyzmq-19.0.1 six-1.15.0 tornado-6.0.4 traitlets-4.3.3 wcwidth-0.2.4\n",
      "Installed kernelspec hats-spark36 in /home/cms.kmotaama/.local/share/jupyter/kernels/hats-spark36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/histogrammar/histogrammar-python.git /tmp/pip-install-w90r8ddv/histogrammar\n",
      "  Running command git checkout -b 1.0.x --track origin/1.0.x\n",
      "  Switched to a new branch '1.0.x'\n",
      "  Branch 1.0.x set up to track remote branch 1.0.x from origin.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "python3.6 -m virtualenv hats-spark36\n",
    "source hats-spark36/bin/activate\n",
    "HISTOGRAMMAR_PATH='git+https://github.com/histogrammar/histogrammar-python.git@1.0.x#egg=histogrammar'\n",
    "pip install ipykernel matplotlib numpy py4j $HISTOGRAMMAR_PATH\n",
    "ipython kernel install --user --name=hats-spark36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "=======\n",
    "\n",
    "If successful, you should see something similar to the following:\n",
    "\n",
    "```\n",
    "New python executable in /home/meloam/hats-template/hats-template/bin/python2\n",
    "Also creating executable in /home/meloam/hats-template/hats-template/bin/python\n",
    "Installing setuptools, pip, wheel...done.\n",
    "/home/meloam/hats-template/hats-template/bin/pip\n",
    "Collecting numpy==1.14.3\n",
    "  Using cached https://files.pythonhosted.org/packages/c0/e7/08f059a00367fd613e4f2875a16c70b6237268a1d6d166c6d36acada8301/numpy-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "<snip>\n",
    "Installed kernelspec hats-template in /home/meloam/.local/share/jupyter/kernels/hats-template\n",
    "```\n",
    "\n",
    "The new kernel you just made will then show up in the various Jupyter dropdowns, allowing you to use it for different notebooks. You can run the [pre-exercises](notebooks/00-preexercise.ipynb) to validate that your environment is properly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "* [Building blocks](notebooks/10-building-blocks.ipynb) - Introduction to the concepts of a Spark-based analysis\n",
    "* [Z-Peak with CMS data](notebooks/20-z-peak.ipynb) - Use Spark to plot the dimuon invariant mass peak\n",
    "\n",
    "## Built With\n",
    "\n",
    "* [Jupyter](http://jupyter.org/) - Interactive python notebook interface\n",
    "* [Apache Spark](http://spark.apache.org/) - Fast and general engine for large-scale data processing\n",
    "* [Spark-ROOT](https://github.com/diana-hep/spark-root) - Scala-based ROOT/IO interface to Spark\n",
    "* [Histogrammar](http://histogrammar.org/) - Functional histogramming framework, optimized for Spark\n",
    "* [MatplotLib](https://matplotlib.org/) - Python plotting library\n",
    "\n",
    "## Authors\n",
    "\n",
    "* **Andrew Melo** - http://lpc.fnal.gov/fellows/2017/Andrew_Melo.shtml\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "* The LPC Distinguished Researcher Program ([link](http://lpc.fnal.gov/fellows/2017.shtml)) - *Support for the author*\n",
    "* Advanced Computing Center for Research and Education (ACCRE) ([link](http://www.accre.vanderbilt.edu/)) - *Host facility and sysadmin support*\n",
    "* The Diana-HEP project ([link](http://diana-hep.org/)) - *Interoperability and compatibility libaries*\n",
    "* Vanderbilt Trans Institutional Program (TIPs) Award ([link](https://vanderbilt.edu/provost/occi/tips.php)) - *Big Data hardware seed funding*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
